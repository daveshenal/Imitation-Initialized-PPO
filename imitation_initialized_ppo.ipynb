{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f19aca",
   "metadata": {},
   "source": [
    "## **Lane-Keeping with Hybrid Imitation and Reinforcement Learning (PPO)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbd2a7",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "- Briefly describe the goal of the project.\n",
    "- Overview of the methodology: CNN for feature extraction via imitation learning and PPO for reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2b1f8",
   "metadata": {},
   "source": [
    "#### 1. Dependencies and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161b753",
   "metadata": {},
   "source": [
    "- Import required libraries (TensorFlow/PyTorch, OpenAI Gym, Carla, NumPy, Matplotlib, etc.).\n",
    "- Set up environment (GPU, paths, etc.).\n",
    "- Any configuration settings (e.g., hyperparameters for PPO, CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793f402",
   "metadata": {},
   "source": [
    "#### 2. Dataset and Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b355d",
   "metadata": {},
   "source": [
    "2.1. Data Collection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39b51e",
   "metadata": {},
   "source": [
    "- Describe how the training dataset is collected (e.g., camera images with corresponding steering angles).\n",
    "- If using [Carla](https://carla.org/) Simulator, explain how the data is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d127fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create imgs folders if it doesn't exist\n",
    "os.makedirs('imgs/semantic', exist_ok=True)\n",
    "os.makedirs('imgs/rgb', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Print details for each datapoint.\n",
    "    - WP Index\n",
    "    - Yaw Adj\n",
    "    - Steer Angle\n",
    "    - Direction\n",
    "    - Is Junction \n",
    "'''\n",
    "\n",
    "import carla\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "\n",
    "sys.path.append('C:/CARLA_0.9.15/PythonAPI/carla')\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "YAW_ADJ_DEGREES = 25  # Maximum yaw angle\n",
    "\n",
    "def get_angle(car, wp):\n",
    "    \"\"\"Calculate angle between car and waypoint\"\"\"\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    distance = ((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    \n",
    "    if distance == 0:\n",
    "        x = 0\n",
    "        y = 0\n",
    "    else:\n",
    "        x = (wp_x - car_x) / distance\n",
    "        y = (wp_y - car_y) / distance\n",
    "        \n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    \n",
    "    # Normalize angle to [-180, 180]\n",
    "    if degrees < -180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    \n",
    "    return degrees\n",
    "\n",
    "def get_distant_angle(car, wp_idx, rte, delta):\n",
    "    \"\"\"Get general direction at a distance ahead\"\"\"\n",
    "    if wp_idx + delta < len(rte) - 1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte) - 1\n",
    "    \n",
    "    # Check for intersection within the look forward\n",
    "    intersection_detected = False\n",
    "    for x in range(i - wp_idx):\n",
    "        if rte[wp_idx + x][0].is_junction:\n",
    "            intersection_detected = True\n",
    "            intersection_ref = wp_idx + x\n",
    "            break\n",
    "    \n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    else:\n",
    "        angles_planned = []\n",
    "        all_angles = []\n",
    "        \n",
    "        junction_wps = rte[intersection_ref][0].get_junction().get_waypoints(carla.LaneType.Driving)\n",
    "        for wp in junction_wps:\n",
    "            angle = int(get_angle(car, wp[1]))\n",
    "            \n",
    "            if wp[1].transform.location.distance(rte[intersection_ref][0].transform.location) > 20:\n",
    "                for i in range(intersection_ref, len(rte) - 1):\n",
    "                    if wp[1].transform.location.distance(rte[i][0].transform.location) < 10:\n",
    "                        angles_planned.append(angle)\n",
    "                    else:\n",
    "                        all_angles.append(angle)\n",
    "        \n",
    "        angles_planned = list(set(angles_planned))\n",
    "        all_angles = list(set(all_angles))\n",
    "        alternative_angles = [item for item in all_angles if item not in angles_planned]\n",
    "        \n",
    "        if len(alternative_angles) == 0 or len(angles_planned) == 0:\n",
    "            result = 0\n",
    "        elif min(angles_planned) < -25 and (min(alternative_angles) > min(angles_planned)):\n",
    "            result = -1  # Left turn\n",
    "        elif max(angles_planned) > 25 and (max(alternative_angles) < max(angles_planned)):\n",
    "            result = 1   # Right turn\n",
    "        else:\n",
    "            result = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "def select_random_route(position, locs, world_map):\n",
    "    \"\"\"Select a random route with minimum distance\"\"\"\n",
    "    point_a = position.location\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world_map, sampling_resolution)\n",
    "    \n",
    "    min_distance = 100\n",
    "    route_list = []\n",
    "    \n",
    "    for loc in locs:\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    \n",
    "    if route_list:\n",
    "        return random.choice(route_list)\n",
    "    return None\n",
    "\n",
    "def cleanup(world):\n",
    "    \"\"\"Destroy all actors\"\"\"\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "def main():\n",
    "    # Connect to CARLA\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    client.set_timeout(10)\n",
    "    world = client.get_world()\n",
    "    \n",
    "    # Configure world settings\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    settings.no_rendering_mode = True\n",
    "    world.apply_settings(settings)\n",
    "    \n",
    "    cleanup(world)\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    \n",
    "    # Test with one route\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    \n",
    "    if vehicle is None:\n",
    "        print(\"Failed to spawn vehicle\")\n",
    "        return\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Generate route\n",
    "    route = select_random_route(start_point, spawn_points, world.get_map())\n",
    "    \n",
    "    if route is None:\n",
    "        print(\"Failed to generate route\")\n",
    "        cleanup(world)\n",
    "        return\n",
    "    \n",
    "    print(f\"Route length: {len(route)} waypoints\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'WP Index':<10} {'Yaw Adj':<10} {'Steer Angle':<15} {'Direction':<12} {'Is Junction':<12}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    gen_dir_angle = 0\n",
    "    \n",
    "    # Test more waypoints to find junctions\n",
    "    test_waypoints = min(100, len(route) - 10)\n",
    "    \n",
    "    for idx in range(test_waypoints):\n",
    "        waypoint = route[idx]\n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        \n",
    "        # Update general direction angle outside intersections\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            gen_dir_angle = get_distant_angle(vehicle, idx, route, 30)\n",
    "        \n",
    "        # Check for lane change\n",
    "        lane_change = False\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            if idx < len(route) - 2:\n",
    "                if route[idx][0].lane_id != route[idx + 1][0].lane_id:\n",
    "                    lane_change = True\n",
    "        \n",
    "        if lane_change:\n",
    "            if get_angle(vehicle, route[idx + 1][0]) < 0:\n",
    "                gen_dir_angle = -1\n",
    "            else:\n",
    "                gen_dir_angle = 1\n",
    "        \n",
    "        # Test with 3 random yaw adjustments per waypoint\n",
    "        for i in range(3):\n",
    "            trans = waypoint[0].transform\n",
    "            angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "            trans.rotation.yaw = initial_yaw + angle_adj\n",
    "            vehicle.set_transform(trans)\n",
    "            time.sleep(0.3)\n",
    "            \n",
    "            if idx + 5 < len(route) - 1:\n",
    "                predicted_angle = get_angle(vehicle, route[idx + 5][0])\n",
    "                \n",
    "                # Determine direction label\n",
    "                direction = gen_dir_angle  # -1, 0, or 1\n",
    "                \n",
    "                is_junction = \"Yes\" if waypoint[0].is_junction else \"No\"\n",
    "                \n",
    "                # Only print if something interesting (junction or direction change)\n",
    "                if waypoint[0].is_junction or gen_dir_angle != 0 or abs(predicted_angle) > 30:\n",
    "                    print(f\"{idx:<10} {angle_adj:+4d}°{'':<5} {predicted_angle:+7.1f}°{'':<6} {direction:+2d}{'':<10} {is_junction:<12}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nTest complete!\")\n",
    "    print(\"\\nLegend:\")\n",
    "    print(\"  Direction: -1 = Left turn, 0 = Straight, +1 = Right turn\")\n",
    "    print(\"  Steer Angle: Angle to waypoint 5 steps ahead\")\n",
    "    print(\"  Yaw Adj: Random yaw adjustment applied to vehicle\")\n",
    "    \n",
    "    cleanup(world)\n",
    "\n",
    "\n",
    "try:\n",
    "    main()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualize data features with realtime front cam footage to confirm its correction.\n",
    "'''\n",
    "\n",
    "import carla\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "sys.path.append('C:/CARLA_0.9.15/PythonAPI/carla')\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "YAW_ADJ_DEGREES = 25  # Maximum yaw angle\n",
    "\n",
    "# Camera settings\n",
    "CAMERA_POS_Z = 1.3\n",
    "CAMERA_POS_X = 1.4\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "FOV = 90\n",
    "\n",
    "def camera_callback(image, data_dict):\n",
    "    \"\"\"Callback for RGB camera\"\"\"\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))[:, :, :3]\n",
    "\n",
    "def get_angle(car, wp):\n",
    "    \"\"\"Calculate angle between car and waypoint\"\"\"\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    distance = ((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    \n",
    "    if distance == 0:\n",
    "        x = 0\n",
    "        y = 0\n",
    "    else:\n",
    "        x = (wp_x - car_x) / distance\n",
    "        y = (wp_y - car_y) / distance\n",
    "        \n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    \n",
    "    # Normalize angle to [-180, 180]\n",
    "    if degrees < -180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    \n",
    "    return degrees\n",
    "\n",
    "def get_distant_angle(car, wp_idx, rte, delta):\n",
    "    \"\"\"Get general direction at a distance ahead\"\"\"\n",
    "    if wp_idx + delta < len(rte) - 1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte) - 1\n",
    "    \n",
    "    # Check for intersection within the look forward\n",
    "    intersection_detected = False\n",
    "    for x in range(i - wp_idx):\n",
    "        if rte[wp_idx + x][0].is_junction:\n",
    "            intersection_detected = True\n",
    "            intersection_ref = wp_idx + x\n",
    "            break\n",
    "    \n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    else:\n",
    "        angles_planned = []\n",
    "        all_angles = []\n",
    "        \n",
    "        junction_wps = rte[intersection_ref][0].get_junction().get_waypoints(carla.LaneType.Driving)\n",
    "        for wp in junction_wps:\n",
    "            angle = int(get_angle(car, wp[1]))\n",
    "            \n",
    "            if wp[1].transform.location.distance(rte[intersection_ref][0].transform.location) > 20:\n",
    "                for i in range(intersection_ref, len(rte) - 1):\n",
    "                    if wp[1].transform.location.distance(rte[i][0].transform.location) < 10:\n",
    "                        angles_planned.append(angle)\n",
    "                    else:\n",
    "                        all_angles.append(angle)\n",
    "        \n",
    "        angles_planned = list(set(angles_planned))\n",
    "        all_angles = list(set(all_angles))\n",
    "        alternative_angles = [item for item in all_angles if item not in angles_planned]\n",
    "        \n",
    "        if len(alternative_angles) == 0 or len(angles_planned) == 0:\n",
    "            result = 0\n",
    "        elif min(angles_planned) < -25 and (min(alternative_angles) > min(angles_planned)):\n",
    "            result = -1  # Left turn\n",
    "        elif max(angles_planned) > 25 and (max(alternative_angles) < max(angles_planned)):\n",
    "            result = 1   # Right turn\n",
    "        else:\n",
    "            result = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "def select_random_route(position, locs, world_map):\n",
    "    \"\"\"Select a random route with minimum distance\"\"\"\n",
    "    point_a = position.location\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world_map, sampling_resolution)\n",
    "    \n",
    "    min_distance = 100\n",
    "    route_list = []\n",
    "    \n",
    "    for loc in locs:\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    \n",
    "    if route_list:\n",
    "        return random.choice(route_list)\n",
    "    return None\n",
    "\n",
    "def cleanup(world):\n",
    "    \"\"\"Destroy all actors\"\"\"\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "def draw_text_on_image(img, lines):\n",
    "    \"\"\"Draw multiple lines of text on image\"\"\"\n",
    "    img_copy = img.copy()\n",
    "    y_offset = 30\n",
    "    for line in lines:\n",
    "        cv2.putText(img_copy, line, (10, y_offset), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        y_offset += 30\n",
    "    return img_copy\n",
    "\n",
    "def main():\n",
    "    # Connect to CARLA\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    client.set_timeout(10)\n",
    "    world = client.get_world()\n",
    "    \n",
    "    # Configure world settings\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    settings.no_rendering_mode = False  # Enable rendering for camera\n",
    "    world.apply_settings(settings)\n",
    "    \n",
    "    cleanup(world)\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "    \n",
    "    # Spawn vehicle\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    \n",
    "    if vehicle is None:\n",
    "        print(\"Failed to spawn vehicle\")\n",
    "        return\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Setup RGB Camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(CAM_WIDTH))\n",
    "    camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(FOV))\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z, x=CAMERA_POS_X))\n",
    "    \n",
    "    camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "    \n",
    "    # Camera data dictionary\n",
    "    camera_data = {'image': np.zeros((CAM_HEIGHT, CAM_WIDTH, 3))}\n",
    "    camera.listen(lambda image: camera_callback(image, camera_data))\n",
    "    \n",
    "    # Wait for first image\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Generate route\n",
    "    route = select_random_route(start_point, spawn_points, world.get_map())\n",
    "    \n",
    "    if route is None:\n",
    "        print(\"Failed to generate route\")\n",
    "        cleanup(world)\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nRoute generated with {len(route)} waypoints\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Press 'n' in console to go to next waypoint, or Ctrl+C to quit\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create OpenCV window\n",
    "    cv2.namedWindow('RGB Camera with Info', cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    # Interactive loop\n",
    "    while True:\n",
    "        # Choose random waypoint (avoid last 10 waypoints)\n",
    "        idx = random.randint(0, len(route) - 11)\n",
    "        waypoint = route[idx]\n",
    "        \n",
    "        # Move vehicle to waypoint\n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        \n",
    "        # Calculate general direction angle\n",
    "        gen_dir_angle = 0\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            gen_dir_angle = get_distant_angle(vehicle, idx, route, 30)\n",
    "        \n",
    "        # Check for lane change\n",
    "        lane_change = False\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            if idx < len(route) - 2:\n",
    "                if route[idx][0].lane_id != route[idx + 1][0].lane_id:\n",
    "                    lane_change = True\n",
    "        \n",
    "        if lane_change:\n",
    "            if get_angle(vehicle, route[idx + 1][0]) < 0:\n",
    "                gen_dir_angle = -1\n",
    "            else:\n",
    "                gen_dir_angle = 1\n",
    "        \n",
    "        # Apply random yaw adjustment\n",
    "        angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "        trans = waypoint[0].transform\n",
    "        trans.rotation.yaw = initial_yaw + angle_adj\n",
    "        vehicle.set_transform(trans)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Calculate steering angle\n",
    "        predicted_angle = get_angle(vehicle, route[idx + 5][0])\n",
    "        \n",
    "        # Get waypoint info\n",
    "        is_junction = \"Yes\" if waypoint[0].is_junction else \"No\"\n",
    "        direction_label = {-1: \"LEFT TURN\", 0: \"STRAIGHT\", 1: \"RIGHT TURN\"}[gen_dir_angle]\n",
    "        \n",
    "        # Print to console\n",
    "        print(f\"\\n--- Waypoint {idx} / {len(route)} ---\")\n",
    "        print(f\"Initial Yaw:     {initial_yaw:.1f}°\")\n",
    "        print(f\"Yaw Adjustment:  {angle_adj:+d}°\")\n",
    "        print(f\"Final Yaw:       {initial_yaw + angle_adj:.1f}°\")\n",
    "        print(f\"Steering Angle:  {predicted_angle:+.1f}°\")\n",
    "        print(f\"Direction:       {gen_dir_angle:+d} ({direction_label})\")\n",
    "        print(f\"Is Junction:     {is_junction}\")\n",
    "        print(f\"Lane Change:     {'Yes' if lane_change else 'No'}\")\n",
    "        \n",
    "        # Display image with text overlay\n",
    "        while True:\n",
    "            if np.sum(camera_data['image']) > 0:\n",
    "                # Prepare text lines\n",
    "                text_lines = [\n",
    "                    f\"Waypoint: {idx}/{len(route)}\",\n",
    "                    f\"Initial Yaw: {initial_yaw:.1f}\",\n",
    "                    f\"Yaw Adj: {angle_adj:+d}\",\n",
    "                    f\"Steer Angle: {predicted_angle:+.1f}\",\n",
    "                    f\"Direction: {gen_dir_angle} ({direction_label})\",\n",
    "                    f\"Junction: {is_junction}\",\n",
    "                    f\"Lane Change: {'Yes' if lane_change else 'No'}\",\n",
    "                    \"\",\n",
    "                    \"Press 'n' for next waypoint\"\n",
    "                ]\n",
    "                \n",
    "                # Draw text on image\n",
    "                display_img = draw_text_on_image(camera_data['image'], text_lines)\n",
    "                cv2.imshow('RGB Camera with Info', display_img)\n",
    "                \n",
    "                # Wait for key press\n",
    "                key = cv2.waitKey(100)\n",
    "                if key == ord('n') or key == ord('N'):\n",
    "                    break\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cleanup(world)\n",
    "\n",
    "\n",
    "try:\n",
    "    main()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nInterrupted by user\")\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Generate Data '''\n",
    "\n",
    "import carla\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('C:/CARLA_0.9.15/PythonAPI/carla') # Carla Path !!\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "\n",
    "SHOW_RGB = False # To display cam footage on a window (Turned off for better performance)\n",
    "\n",
    "# Cam position relative to the vehicle\n",
    "CAMERA_POS_Z = 1.3\n",
    "CAMERA_POS_X = 1.4\n",
    "\n",
    "# Image size\n",
    "CAM_HEIGHT = 480\n",
    "CAM_WIDTH = 640\n",
    "\n",
    "FOV = 90\n",
    "\n",
    "YAW_ADJ_DEGREES = 25 # Maximum yaw angle\n",
    "\n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def sem_callback(image,data_dict):\n",
    "    #change for Semantic camera\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "def cleanup(): # Destroy all the actors in the simulation\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for actor in world.get_actors().filter('*sensor*'):\n",
    "        actor.destroy()\n",
    "\n",
    "\n",
    "# Angle between the car and waypoint\n",
    "def get_angle(car,wp):\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    if ((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5 == 0:\n",
    "        x=0\n",
    "        y=0\n",
    "    else:\n",
    "        x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "        \n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "# get angle to a waypoint at a distance\n",
    "def get_distant_angle(car,wp_idx,rte, delta):\n",
    "    if wp_idx + delta < len(rte)-1:\n",
    "        i = wp_idx + delta\n",
    "    else:\n",
    "        i = len(rte)-1\n",
    "    # check for intersection within the look forward\n",
    "    # so we do not give turn results when just following the road\n",
    "    intersection_detected = False\n",
    "    for x in range(i-wp_idx):\n",
    "        if rte[wp_idx+x][0].is_junction:\n",
    "             intersection_detected = True\n",
    "             intersection_ref = wp_idx+x\n",
    "             break\n",
    "    if not intersection_detected:\n",
    "        result = 0\n",
    "    else: # check out the intersection\n",
    "        angles_planned = [] # list of angles towards current exit from the intersection\n",
    "        all_angles = []\n",
    "        \n",
    "        junction_wps = rte[intersection_ref][0].get_junction().get_waypoints(carla.LaneType.Driving)\n",
    "        for wp in junction_wps:\n",
    "            angle = int(get_angle(car,wp[1])) \n",
    "\n",
    "            if wp[1].transform.location.distance(route[intersection_ref][0].transform.location) > 20: \n",
    "  \n",
    "                for i in range(intersection_ref,len(route)-1):\n",
    "                    if wp[1].transform.location.distance(route[i][0].transform.location) < 10:\n",
    "                        angles_planned.append(angle)\n",
    "                    else:\n",
    "                        all_angles.append(angle)\n",
    "        angles_planned = list(set(angles_planned))\n",
    "        all_angles = list(set(all_angles))\n",
    "        alternative_angles = [item for item in all_angles if item not in angles_planned] \n",
    "        if len(alternative_angles) == 0 or len(angles_planned) == 0:\n",
    "            result = 0\n",
    "        elif min(angles_planned)<-25 and (min(alternative_angles) > min(angles_planned)):\n",
    "            #we are planning left turn\n",
    "            result = -1\n",
    "        elif max(angles_planned)>25 and (max(alternative_angles) < max(angles_planned)):\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0  \n",
    "    return result\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    point_a = position.location #start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: \n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "def main():\n",
    "    client = carla.Client('localhost', 2000)\n",
    "    time.sleep(5) # just in case\n",
    "    client.set_timeout(10) # increase if failed to connect in time or check for port 2000 \n",
    "    world = client.get_world()\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    settings.no_rendering_mode = True\n",
    "    if settings.synchronous_mode:\n",
    "        settings.fixed_delta_seconds = 0.05\n",
    "    world.apply_settings(settings)\n",
    "\n",
    "    cleanup()\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "    while True:\n",
    "        start_point = random.choice(spawn_points)\n",
    "        vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "        vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "        time.sleep(2)\n",
    "    \n",
    "        # RGB CAM\n",
    "        camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "        camera_bp.set_attribute('image_size_x', str(CAM_WIDTH))\n",
    "        camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "        camera_bp.set_attribute('fov', str(FOV))\n",
    "        camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "\n",
    "        camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "        image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "        image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "        camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "                    'sem_image': np.zeros((image_h,image_w,3))}\n",
    "        \n",
    "        camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "        # Semantic cam\n",
    "        sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "        sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH))\n",
    "        sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "        sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "    \n",
    "        sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "        \n",
    "        sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "        if SHOW_RGB:\n",
    "            cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "            cv2.imshow('RGB Camera',camera_data['image'])\n",
    "        \n",
    "        route = select_random_route(start_point,spawn_points)\n",
    "        gen_dir_angle = 0 # in case we did not get a general GPS direction\n",
    "        for idx, waypoint in enumerate(route): # move the car through the route (Not real navigation !!!)\n",
    "            \n",
    "            transform = waypoint[0].transform\n",
    "            vehicle.set_transform(transform)\n",
    "            vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "            time.sleep(2)\n",
    "            initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "            # GPS general direction is only taken outside intersections\n",
    "            if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "                gen_dir_angle = get_distant_angle(vehicle,idx,route,30) # general angle taken before spinning the car\n",
    "            # logic to detect a lane change and ignore/not take those images\n",
    "            lane_change = False\n",
    "            if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "                if idx < len(route)-2:\n",
    "                    if route[idx][0].lane_id != route[idx+1][0].lane_id:\n",
    "                        lane_change = True\n",
    "            if lane_change: # lane changes are treated as turns in general direction\n",
    "                if get_angle(vehicle,route[idx+1][0])<0:\n",
    "                    gen_dir_angle = -1\n",
    "                else:\n",
    "                    gen_dir_angle = 1\n",
    "\n",
    "            for i in range(5):\n",
    "                trans = waypoint[0].transform\n",
    "                angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "                trans.rotation.yaw = initial_yaw +angle_adj \n",
    "                vehicle.set_transform(trans)\n",
    "                vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "                time.sleep(1) \n",
    "                \n",
    "                \n",
    "                if SHOW_RGB:\n",
    "                    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "                \n",
    "                if idx +5 < len(route)-1: # Check for end of the route\n",
    "                    predicted_angle = get_angle(vehicle,route[idx+5][0]) # we always get the angle to +5 waypoint ahead of us\n",
    "                    \n",
    "                    time_grab = time.time_ns()\n",
    "                    rgb_image = camera_data['image']\n",
    "                    sem_image = camera_data['sem_image']\n",
    "                    if np.sum(sem_image) > 0: #check for black images (This not work if image has at least one rgb value)\n",
    "                        # So make sure to check the dataset before train the model\n",
    "                        cv2.imwrite('imgs/semantic/%019d_%s_%s.png' % (time_grab, gen_dir_angle, round(predicted_angle,0)), sem_image)\n",
    "                        cv2.imwrite('imgs/rgb/%019d_%s_%s.png' % (time_grab, gen_dir_angle, round(predicted_angle,0)), rgb_image)\n",
    "    cleanup()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "try:\n",
    "    main()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nInterrupted by user\")\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d33ee",
   "metadata": {},
   "source": [
    "2.2. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db618800",
   "metadata": {},
   "source": [
    "- Segmentation of camera images (any transformations, resizing)\n",
    "- Normalization of steering angles\n",
    "- Visualizations of segmented images to show what the model will see"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cb490",
   "metadata": {},
   "source": [
    "#### 3. Stage 1: Imitation Learning with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edda8e",
   "metadata": {},
   "source": [
    "3.1. Model Architecture:\n",
    "- Define and explain the CNN architecture.\n",
    "- Example: Convolutional layers, pooling, fully connected layers, output layer (steering angle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a819206",
   "metadata": {},
   "source": [
    "3.2. Training the CNN:\n",
    "- Loss function (e.g., Mean Squared Error).\n",
    "- Optimizer (e.g., Adam).\n",
    "- Training loop and evaluation.\n",
    "- Visualize loss curve and predictions vs. ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08531eb7",
   "metadata": {},
   "source": [
    "3.3. Feature Extraction:\n",
    "- Remove the last layer of the CNN and show how the feature vector is extracted.\n",
    "- Example: Demonstrate the dimensionality of the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6338c0b",
   "metadata": {},
   "source": [
    "#### 4. Stage 2: Integration with PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588f3e7",
   "metadata": {},
   "source": [
    "4.1. PPO Setup:\n",
    "- Define PPO architecture for the lane-keeping task.\n",
    "- Explain how the feature vector from the CNN is used as the input to PPO’s observation space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44708c3e",
   "metadata": {},
   "source": [
    "4.2. Action and Reward Setup:\n",
    "- Actions (steering angle or continuous control for steering, throttle, brake).\n",
    "- Reward function (e.g., staying in the center of the lane, penalty for lane departure)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29447e58",
   "metadata": {},
   "source": [
    "4.3. Training PPO:\n",
    "- PPO training loop (number of episodes, time steps).\n",
    "- Visualize training progress (e.g., reward over time, lane-keeping performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10adc519",
   "metadata": {},
   "source": [
    "#### 5. Evaluation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d211d9",
   "metadata": {},
   "source": [
    "5.1. Evaluation Setup:\n",
    "- Test the agent in different lane-keeping scenarios (e.g., straight roads, curves, and obstacles).\n",
    "- Visualize the agent’s lane-keeping behavior using real-time plots.\n",
    "\n",
    "5.2. Metrics:\n",
    "- Lane center distance, steering smoothness.\n",
    "- Visualizations: A side-by-side comparison of the agent’s trajectory versus ideal lane center.\n",
    "\n",
    "5.3. Discussion:\n",
    "- Compare results with baseline (if any) or human-driven performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e8513",
   "metadata": {},
   "source": [
    "#### 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d41a3",
   "metadata": {},
   "source": [
    "- Summarize the key takeaways from the project.\n",
    "- Reflect on the challenges, the success of combining imitation learning with PPO, and possible improvements (e.g., better reward design, adding more sensors, fine-tuning CNN during RL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78e017",
   "metadata": {},
   "source": [
    "#### 7. Future Work and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d551b8",
   "metadata": {},
   "source": [
    "- Discuss ideas for improving the system or extending it to more complex driving tasks (e.g., adding obstacle avoidance, handling diverse weather conditions).\n",
    "- Suggest how the model could be generalized to different types of vehicles or environments (e.g., real-world data, simulations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefa053",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red; font-style:italic;\">Final Checklist:</h3>\n",
    "\n",
    "- *Comments & Markdown: Thorough explanations for each code block.*\n",
    "- *Visualizations: Graphs (loss curves, steering predictions), lane visualizations, etc.*\n",
    "- *Modularity: Keep each section modular so that it’s easy to follow, run, and modify.*\n",
    "- *Documentation: Each code section should have accompanying comments to explain what’s being done.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
